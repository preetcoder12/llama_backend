services:
  - type: web
    name: llama-backend
    env: docker
    dockerfilePath: ./Dockerfile
    plan: free
    healthCheckPath: /health
    envVars:
      - key: OLLAMA_URL
        value: http://localhost:11434
      - key: MODEL_NAME
        value: tinyllama:1.1b
      - key: PORT
        value: 3000
      - key: NODE_ENV
        value: production
    buildCommand: echo "Using Dockerfile"
    startCommand: ./start.sh
    region: oregon
    branch: main
    autoDeploy: true